
All the codes for the genome analysis.

1.0 Genome survey
# We used Genomescope 2.0 to conduct the genome survey
## First, Jellfish was used to count the k-mers with this command:
```
1) jellyfish count -C -m 21 -s 1000000000 -t 10 *.fastq -o reads.jf
2) jellyfish histo -t 10 reads.jf > reads.histo
```
## Then, the reads.histo was uploaded to the website to genomescope2(http://qb.cshl.edu/genomescope/genomescope2.0/)

# Smudgeplot 
## Commands:
```
   ls *.fastq.gz > FILES
   kmc -k21 -t16 -m64 -ci1 -cs10000 @FILES kmcdb tmp
   kmc_tools transform kmcdb histogram kmcdb_k21.hist -cx10000   
   L=$(smudgeplot.py cutoff kmcdb_k21.hist L)
   U=$(smudgeplot.py cutoff kmcdb_k21.hist U)
   echo $L $U 
   kmc_tools transform kmcdb -ci"$L" -cx"$U" reduce kmcdb_L"$L"_U"$U"
   smudge_pairs kmcdb_L"$L"_U"$U" kmcdb_L"$L"_U"$U"_coverages.tsv kmcdb_L"$L"_U"$U"_pairs.tsv > kmcdb_L"$L"_U"$U"_familysizes.tsv 
   smudgeplot.py plot kmcdb_L"$L"_U"$U"_coverages.tsv
```

2.0 Genome assembly
# First, Nextdenovo 2.0 (https://github.com/Nextomics/NextDenovo) was used to conduct the genome assembly

The configure file:

```
[General]
job_type = local
job_prefix = nextDenovo
task = all # 'all', 'correct', 'assemble'
rewrite = yes # yes/no
deltmp = yes
rerun = 3
parallel_jobs = 1
input_type = raw
input_fofn = ./fofn
workdir = ./lg

[correct_option]
read_cutoff = 1k
seed_cutoff = 25k
blocksize = 1g
pa_correction = 5
seed_cutfiles = 5
sort_options =  -m 5g -t 5 -k 50
minimap2_options_raw = -x ava-ont -t 8
correction_options = -p 5

[assemble_option]
minimap2_options_cns = -x ava-ont -t 8 -k17 -w17
nextgraph_options = -a 1
```

# Second, Pilon (https://github.com/broadinstitute/pilon/wiki) was used to polish the genome assembly with six rounds of iteration

The first round:

```
         bwa index nd.ref.fa
		 bwa mem -t 100 nd.ref.fa ngs_R1.fq.gz ngs_R2.fq.gz |samtools view -bS ->aligned.bam
         samtools sort -o aligned.srt.bam aligned.bam
         samtools index aligned.srt.bam 
         java -Xmx10G -jar pilon-1.23.jar --genome nd.ref.fa --frags aligned.srt.bam --output nd.ref.pilon.out		 
```

# Third, annotated the polished genome assembly towards the contigs (Ar.contigs.fa)

       ## Prepare the input for the Marker-P pipeline 
	   ### Repeat library construction using EDTA (https://github.com/oushujun/EDTA)
```
	   perl EDTA.pl --genome Ar.contigs.fa --overwrite 1 --sensitive 1 --anno 1 --evaluate 1 --threads 10
```
	   ### Proteins
	   download the proteins from seven sequenced plants (including Brassica oleracea, Eutrema salsugineu, Alyssum linifolium, Arabidopsis thaliana, Boechera stricta, Capsella rubella and C. grandiflora) and a total of 1,440 benchmarking universal single-copy orthologues from the Embryophyta within BUSCO.
	
       ### Transcripts
```	   
	   Trinity --seqType fq --left reads_1.fq --right reads_2.fq --CPU 6 --max_memory 20G 
```	   
	   
       ### Training ab initio Gene Predictors
	   
           Augustus:
		   We trained ab initio Gene Predictors (SNAP) according the following link https://vcru.wisc.edu/simonlab/bioinformatics/programs/augustus/docs/tutorial2015/training.html
       	   SNAP: 
		   We trained ab initio Gene Predictors (SNAP) according the following link: http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/MAKER_Tutorial_for_GMOD_Online_Training_2014#Training_ab_initio_Gene_Predictors
	   ## Annotated the contigs using MAKER-P 
```
            mpiexc -n 80 maker  
```
       We will obtain the annotaion of the polished contigs (Ar.contigs.fa)  

		
# Identify the syntenic blocks and synlogs using JCVI (https://github.com/tanghaibao/jcvi/wiki/MCscan-(Python-version)) Input file (Ar.ctg.gff)
```   
   python -m jcvi.formats.gff bed --type=mRNA --key=Name Ar.ctg.gff -o Ar.ctg.bed
   python -m jcvi.compara.catalog ortholog Ar.ctg Ar.ctg --no_strip_names --cscore=.99 
   python -m jcvi.graphics.dotplot Ar.ctg.Ar.ctg.anchors         
``` 

# Calculate KaKs of the synlogs in the syntenic blocks  

```
       ParaAT.pl -p processors -a pep.fa -n cds.fa -k kaks -f axt -o kaks.out
```
we will obtain the syntenic contigs based on the Ks (syntenic_pair_file)

# Process the HiC reads using juicer pipleline and generate the "Merged_nodup.txt" (https://github.com/aidenlab/juicer)

```
cd references
bwa index Ar.contigs.fa
./generate_site.py MboI Ar.contigs.fa Ar.contigs.fa 
fastalength Ar.contigs.fa |awk '{print$2"\t"$1}'  >chrom.sizes
cd ../
./scripts/juicer.sh -t 50 -d ./ -s MboI -p ./references/chrom.sizes -z references/Ar.contigs.fa -y references/Ar.contigs.fa_MboI.txt -D ./

```

# remove the links across the syntenic contigs

```
     perl  remove_pair.pl syntenic_pair_file Merged_nodup.txt >filted_Merged_nodup.txt
``` 

# Scaffolding using the 3D-DNA pipeline
     
```
	  run-asm-pipeline.sh -r 0 Ar.contigs.fa filted_Merged_nodup.txt
```

# Fine-tuning the genome assembly using juicerbox and generate the final file 

```
     run-asm-pipeline-post-review.sh -r cns2.FINAL.review1106.assembly Ar.contigs.fa filted_Merged_nodup.txt
	 
```
We will obtain the final file (ref.genome.fa)
	   
3.0 subgenome partion
  
#  partition and phase subgenomes using subphaser software (https://github.com/zhangrengang/SubPhaser)


```
      subphaser -i ref.genome.fa -c sg.config  -k 13 -q 100 -f 2 
      subphaser -i ref.genome.fa -c sg.config  -k 15 -q 100 -f 2
	  subphaser -i ref.genome.fa -c sg.config -k 13 -q 200 -f 2  
``` 
4.0 Genome annotation

Annotating the genome assembly using Marker-P pipeline as we described above (2.0)

5.0 Genome evaluation and comparative genomic analysis 

# evaluting the genome/gene sets using BUSCO

```     
   BUSCO.py -i genome.fa -o busco.out -l ./embryophyta_odb10 -m geno
   BUSCO.py -i cds.fa -o busco.cds.out -l ./embryophyta_odb10 -m tran
```
# evaluating the genome using LAI

 ###To obtain raw input files with LTRharvest and LTR_FINDER_parallel:

```
   gt suffixerator -db genome.fa -indexname genome.fa -tis -suf -lcp -des -ssp -sds -dna
   gt ltrharvest -index genome.fa -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 -motif TGCA -motifmis 1 -similar 85 -vic 10 -seed 20 -seqids yes > genome.fa.harvest.scn
   LTR_FINDER_parallel -seq genome.fa -threads 10 -harvest_out -size 1000000 -time 300
   cat genome.fa.harvest.scn genome.fa.finder.combine.scn > genome.fa.rawLTR.scn
```
  ## To run LTR_retriever
```
   LTR_retriever -genome genome.fa -inharvest genome.fa.rawLTR.scn -threads 10
```
  ## To run LAI
```  
   LAI -genome genome.fa -intact genome.fa.pass.list -all genome.fa.out
```

# evaluating the genome using read re-mapping ration

   ## Map Illumina reads to the genome
```
      bwa index genome.fa 
      bwa mem genome.fa read1.fa read2.fa |samtools view -bS-> genome.bam   	  
```  
   ## Map Nanopore reads to the genome 
```
     minimap2 -x map-ont -o nanopore.sam -a genome.fa reads.fa
```

# Conduct the genome assembly using Pacbio HIFI

```
  hifiasm -l 2 -o hifi.asm -t 100 hifi.reads.fa  
```

# Create an interactive dot plot using dotplotly (https://github.com/tpoorten/dotPlotly)

 ## Map using minimap2

```
   minimap2 -x asm5 nanopore.genome.fa hifi.contigs.fa > cmp.minimap2.paf
```
 ## create dotplot

``` 
   pafCoordsDotPlotly.R -i cmp.minimap2.paf -o cmp.minimap2.plot -m 2000 -q 500000 -k 10 -s -t -l -p 12 
```

6.0 Genome evolution

# generate orthogroups gene sets using orthofinder software

```
   OrthoFinder/orthofinder -f data/
```

7.0 whole-genome methylation analysis

# aligning the reads to the genome using bismark (https://github.com/FelixKrueger/Bismark)

```
       bismark_genome_preparation --hisat2 genome_folder 
	   bismark --genome genome_folder -1 leaf_R1.fq.gz -2 leaf_R2.fq.gz -o leaf.bam
	   deduplicate_bismark --bam leaf.bam
	   bismark_methylation_extractor --gzip --bedGraph Leaf_R1_bismark_hisat2_pe.deduplicated.bam
```

# Call the methylation using Nanopolish 

##Index the output of the basecaller
```
nanopolish index -d /path/to/raw_fast5s/ -s sequencing_summary.txt basecalled_output.fastq # for FAST5 inout
nanopolish index basecalled_output.fastq --slow5 signals.blow5 # for SLOW5 input
```
# Index the draft genome
```
bwa index draft.fa
```
# Align the basecalled reads to the draft sequence
```
bwa mem -x ont2d -t 8 draft.fa reads.fa | samtools sort -o reads.sorted.bam -T reads.tmp -
samtools index reads.sorted.bam
nanopolish call-methylation -t 8 -r output.fastq -b output.sorted.bam -g reference.fasta  > methylation_calls.tsv
scripts/calculate_methylation_frequency.py methylation_calls.tsv > methylation_frequency.tsv
```

# deeptools (https://deeptools.readthedocs.io/en/develop/)

  ## install the deeptools using docker (https://www.docker.com/)
  ## run the deeptools to obtain the matrix   

```
docker run -v $PWD:/root -w /root dukegcb/deeptools computeMatrix scale-regions -S r.cg.bedGraph.bw \
 s.cg.bedGraph.bw \
 l.cg.bedGraph.bw \
 -R Ar1017.bed --beforeRegionStartLength 3000 --regionBodyLength 5000 --afterRegionStartLength 3000 --skipZeros -o cg.gene.mat.gz -bs 40
```
 ## draw the profile aound the genes 

```
    docker run -v $PWD:/root -w /root dukegcb/deeptools  plotProfile  --matrixFile cg.gene.mat.gz --outFileName cg.pdf
```
 
8.0 3D-genomic analysis

# The clean reads were mapped against their corresponding reference genomes with Juicer software
```
./scripts/juicer.sh -t 50 -d ./ -s MboI -p ./references/chrom.sizes -z references/Ar.contigs.fa -y references/Ar.contigs.fa_MboI.txt -D ./
```
#The contact matrices were generated at different resolutions (10, 25, 50, 100 kb) using hicConvertFormat in HiCExplorer

```
 hicConvertFormat -m inter_30.hic --inputFormat hic --outputFormat cool --outFileName jj.cool -r 10000
 hicConvertFormat -m inter_30.hic --inputFormat hic --outputFormat cool --outFileName jj.cool -r 25000
 hicConvertFormat -m inter_30.hic --inputFormat hic --outputFormat cool --outFileName jj.cool -r 50000
 hicConvertFormat -m inter_30.hic --inputFormat hic --outputFormat cool --outFileName jj.cool -r 100000
```

# The hicPCA program embedded in HiCExplorer was used to delineate A/B compartments at a 50-kb resolution
```
   hicPCA --matrix jj.50k.cool --outputFileName A_B --whichEigenvectors 1
```
# TAD-like structures were identified using the hicFindTADs program embedded in HiCExplorer at the different resolutions

```
   hicFindTADs  --matrix  lg_50000.cool --outPrefix 50k --correctForMultipleTesting fdr
   hicFindTADs  --matrix  lg_10000.cool --outPrefix 10k --correctForMultipleTesting fdr
   hicFindTADs  --matrix  lg_25000.cool --outPrefix 25k --correctForMultipleTesting fdr
   hicFindTADs  --matrix  lg_100000.cool --outPrefix 100k --correctForMultipleTesting fdr
```

#The Fit-Hi-C (v2.05) tool was used to identify the Hi-C interaction peaks at a 10-kb resolution

```
  fithic -i fithic.interactionCounts.gz -f fithic.fragmentMappability.gz -r 10000 -x intraOnly
```

## FDR < 0.00001 and contactCount > 10 were used to obtain the candidate interaction sites.
 

9.0 LTR analysis 
We conducted the LTR analysis using the in-house pipeline Valcano 
The description for the pipeline https://maypoleflyn.github.io/2021-02-01-Val/
User could find the code https://github.com/maypoleflyn/valcano 












   	   
	      
	   
    
